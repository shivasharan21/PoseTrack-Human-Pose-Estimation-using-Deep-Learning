# Training configuration for pose estimation models

# Model configuration
model:
  type: "hrnet"  # hrnet, openpose, mediapipe
  num_keypoints: 17
  input_size: [256, 256]
  output_stride: 4

# Training parameters
training:
  epochs: 100
  batch_size: 16
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: "adam"  # adam, sgd, adamw
  scheduler: "step"  # step, cosine, plateau
  scheduler_step_size: 30
  scheduler_gamma: 0.1
  grad_clip: 1.0

# Loss function configuration
loss:
  type: "mse"  # mse, l1, focal, wing
  keypoint_weight: 1.0
  heatmap_weight: 1.0
  paf_weight: 1.0
  smooth_loss_weight: 0.1

# Data configuration
data:
  train_data_dir: "data/train"
  val_data_dir: "data/val"
  annotations_file: "data/annotations.json"
  num_workers: 4
  pin_memory: true
  
  # Augmentation settings
  augmentation:
    horizontal_flip: 0.5
    rotation: 30
    brightness_contrast: 0.2
    saturation: 0.2
    gauss_noise: 0.2
    blur: 0.2

# Output configuration
output:
  output_dir: "output/training"
  save_interval: 10
  log_interval: 100

# Callbacks configuration
callbacks:
  early_stopping:
    enabled: true
    monitor: "val_loss"
    patience: 10
    min_delta: 0.001
    restore_best_weights: true
  
  model_checkpoint:
    enabled: true
    filepath: "output/training/best_model.pth"
    monitor: "val_loss"
    save_best_only: true
    save_freq: 1
  
  tensorboard:
    enabled: true
    log_dir: "output/training/logs"
    log_freq: 1
  
  lr_scheduler:
    enabled: true
    scheduler_type: "reduce_on_plateau"
    monitor: "val_loss"
    patience: 5
    factor: 0.5
    min_lr: 1e-6

# Evaluation configuration
evaluation:
  metrics:
    - "pck"
    - "mpjpe"
    - "oks"
  thresholds: [0.1, 0.2, 0.3, 0.4, 0.5]
  save_predictions: true
  visualize_results: true

# Hardware configuration
hardware:
  device: "auto"  # auto, cpu, cuda
  mixed_precision: true
  dataloader_pin_memory: true
